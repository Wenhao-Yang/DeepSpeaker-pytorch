# @Author: yangwenhao
# @Contact: 874681044@qq.com
# @Software: PyCharm
# @File: aidata_resnet.yaml
# @Time: 2022/09/30 09:15
# @Overview:

data_root_dir: /home/yangwenhao/project/lstm_speaker_verification

## Dataset
seed: 123456
datasets: vox1
testset: vox1
feat_type: wave
loss: arcsoft
input_dim: 80
# trans_fbank: True
feat: int
wav_type: int
subset: ""
sample_type: instance

train_dir: !ref <data_root_dir>/data/<datasets>/dev_orgsnr1
# <subset>_<feat>
train_test_dir: !ref <data_root_dir>/data/<testset>/test<subset>
train_trials: trials
valid_dir: !ref <data_root_dir>/data/<datasets>/train_valid_<feat>
num_valid: 2
test_dir: !ref <data_root_dir>/data/<testset>/test
trials: trials
input_norm: Mean

test_input: fix
log_scale: False
sr: 16000
# transform
chunk_size: 64000

# padding
random_chunk: [32000, 32000]
frame_shift: 48000 # test shift

# train dataset config
num_frames: 64000
segment_shift: 32000

# sample_type: instance
input_per_spks: 768
extract: True
nj: 6
shuffle: False
batch_shuffle: True

feat_format: wav
remove_vad: False

### Training settings
epochs: 18

# optimizer
optimizer: adam
lr_decay: 0
weight_decay: 0.00002
second_wd: 0.0002
dampening: 0
nesterov: False
momentum: 0.9
accu_steps: 1

# Scheduler
patience: 3
milestones: [10, 20, 30, 40]
scheduler: cyclic
lr: 0.001
base_lr: 0.00000001
cyclic_epoch: 3
# step_size: 65000
cos_sim: True

early_stopping: True
early_patience: 20
early_delta: 0.001
early_meta: "mix8"

## model Setttings
model: ECAPA_brain
kernel_size:
alpha: 0
embedding_size: 192
batch_size: 96
dropout_p: 0.0
activation: relu
channels: 512,512,512,512,1536 #[512, 512, 512, 512, 1536]
#channels: [1024,1024,1024,1024,3072]
encoder_type: "SASP2"
num_classes: 1211
mask: fdrl

embedding_model: !new:Define_Model.TDNN.ECAPA_brain.ECAPA_TDNN
  mask: !ref <mask>
  filter: "fbank"
  sr: 16000
  feat_dim: !ref <input_dim>
  input_dim: !ref <input_dim>
  input_norm: !ref <input_norm>
  num_classes: !ref <num_classes>
  channels: [256, 256, 256, 256, 768]

augment_wavedrop: !new:speechbrain.lobes.augment.TimeDomainSpecAugment
  sample_rate: !ref <sr>
  speeds: [100]

augment_speed: !new:speechbrain.lobes.augment.TimeDomainSpecAugment
  sample_rate: !ref <sr>
  speeds: [95, 100, 105]

# rir_folder: /home/yangwenhao/project/lstm_speaker_verification/data/rir #!ref <data_folder> # Change it if needed
rir_folder: '/data2022/yangwenhao/dataset'
musan_lst: '/home/yangwenhao/project/SpeakerVerification-pytorch/Misc/audio_processing/musan_4s_nospeech.csv'

add_rev: !new:speechbrain.lobes.augment.EnvCorrupt
   openrir_folder: !ref <rir_folder>
   openrir_max_noise_len: 3.0  # seconds
   reverb_prob: 1.0
   noise_prob: 0.0
   noise_snr_low: 0
   noise_snr_high: 15
   rir_scale_factor: 1.0

add_noise: !new:speechbrain.lobes.augment.EnvCorrupt
   openrir_folder: !ref <rir_folder>
   openrir_max_noise_len: 3.0  # seconds
   reverb_prob: 0.0
   noise_prob: 1.0
   noise_snr_low: 0
   noise_snr_high: 15
   rir_scale_factor: 1.0

add_rev_noise: !new:speechbrain.lobes.augment.EnvCorrupt
   openrir_folder: !ref <rir_folder>
   openrir_max_noise_len: 3.0  # seconds
   reverb_prob: 1.0
   noise_prob: 1.0
   noise_snr_low: 0
   noise_snr_high: 15
   rir_scale_factor: 1.0

add_musan_noise: !new:speechbrain.lobes.augment.EnvCorrupt
   noise_csv: !ref <musan_lst>
   openrir_max_noise_len: 3.0  # seconds
   reverb_prob: 0.0
   noise_prob: 1.0
   noise_snr_low: 0
   noise_snr_high: 15
   rir_scale_factor: 1.0

augment_pipeline: [
   !ref <augment_wavedrop>,
   !ref <augment_speed>,
   !ref <add_rev>,
   !ref <add_noise>,
   !ref <add_rev_noise>,
]

# augment_pipeline: [ ]
concat_augment: True
num_pipes: 3
bandpass: [20, 3000]
band_pass_prob: 0.5
band_order: 8
# sample_score: loss
# sample_ratio: 0.75
# rest_prob: 0.2

# loss
loss_ratio: 1
lr_ratio: 0
loss_lambda: False
loss_type: !ref <loss>
margin: 0.2
# m: 0.2
s: 30
#lamda_beta: 0.2
#mixup_type: input
lamda_beta: 2
proser_gamma: 1
#_<proser_gamma>
mixup_layer: [1, 2, 3]
mixup_type: ''
# stat_type: margin1

# Checkpoints
loss_str: ""
check_path: !ref Data/checkpoint/<model>/<input_norm>_batch<batch_size>_<encoder_type>_em<embedding_size><loss_str>_official_2ses<early_meta>/<loss>_<optimizer>_<scheduler>/<datasets>/<feat_type>_fb<input_dim>_orgsnr1_band05_aug5<num_pipes>_<mask>theta05

save_data_dir: Data/checkpoint/ECAPA_brain/Mean_batch192_SASP2_em192_official_2sesmix8/arcsoft_adam_cyclic/vox1/wave_fb80_dist_orgsnr1
#_lamda<lamda_beta>
#_mixup<lamda_beta>_<mixup_type>
# _red<red_ratio>
resume: !ref <check_path>/checkpoint_17.pth

veri_pairs: 9600
gpu_id: 0,1

test_interval: 4
log_interval: 10
