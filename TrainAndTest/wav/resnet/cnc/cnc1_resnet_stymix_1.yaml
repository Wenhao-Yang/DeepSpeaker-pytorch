# @Author: yangwenhao
# @Contact: 874681044@qq.com
# @Software: PyCharm
# @File: aidata_resnet.yaml
# @Time: 2022/09/30 09:15
# @Overview:

data_root_dir: /home/yangwenhao/project/lstm_speaker_verification

## Dataset
seed: 123456
datasets: cnceleb
testset: cnceleb
feat_type: wave
loss: arcsoft
input_dim: 80
feat: int
subset: ''

train_dir: !ref <data_root_dir>/data/<datasets>/egs/<feat_type>/dev<subset>
train_test_dir: !ref <data_root_dir>/data/<testset>/test
train_trials_path: !ref <data_root_dir>/data/<testset>/test/trials_2w
train_trials: trials
num_valid: 0.05
valid_dir: !ref <data_root_dir>/data/<datasets>/egs/<feat_type>/dev_valid
test_dir: !ref <data_root_dir>/data/<testset>/test
trials: trials
input_norm: Mean
input_per_spks: 768

test_input: fix
log_scale: False
random_chunk: [32000, 32000]
chunk_size: 48000
frame_shift: 48000
extract: True
nj: 8
shuffle: False
batch_shuffle: True

feat_format: wav
wav_type: int
remove_vad: False


### Training settings
epochs: 60

# optimizer
optimizer: adam
lr_decay: 0
weight_decay: 0.00001
dampening: 0
nesterov: False
momentum: 0.9
accu_steps: 1


# Scheduler
patience: 3
milestones: [ 10,20,30,40 ]
scheduler: cyclic
lr: 0.002
base_lr: 0.00000001
cos_sim: True
cyclic_epoch: 5


early_stopping: True
early_patience: 15
early_delta: 0.001
early_meta: "mix8"

## model Setttings
resnet_size: 18
block_type: 'seblock'
red_ratio: 2
encoder_type: 'SAP2'
downsample: 'k1'
model: ThinResNet
kernel_size:
alpha: 0
avg_size: 5
embedding_size: 256
batch_size: 256
dropout_p: 0.05
activation: relu
channels: 32,64,128,256
fast: none1
num_classes: 797

embedding_model: !new:Define_Model.ResNet.ThinResNet
  resnet_size: !ref <resnet_size>
  filter: "fbank"
  sr: 16000
  win_length: 400
  nfft: 512
  feat_dim: !ref <input_dim>
  input_dim: !ref <input_dim>
  input_norm: !ref <input_norm>
  block_type: !ref <block_type>
  downsample: !ref <downsample>
  red_ratio: !ref <red_ratio>
  fast: !ref <fast>
  alpha: !ref <alpha>
  kernel_size: [7, 7]
  padding: [3, 3]
  stride: [1, 2]
  channels: [16, 32, 64, 128]
  dropout_p: !ref <dropout_p>
  avg_size: !ref <avg_size>
  encoder_type: !ref <encoder_type>
  embedding_size: !ref <embedding_size>
  num_classes: !ref <num_classes>
  activation: relu

classifier: !new:Define_Model.Loss.SoftmaxLoss.AdditiveMarginLinear
  feat_dim: !ref <embedding_size>
  num_classes: !ref <num_classes>


# loss
loss_ratio: 1
lr_ratio: 0
loss_lambda: False
loss_type: !ref <loss>
margin: 0.2
# m: 0.2
s: 30
lamda_beta: 2
proser_gamma: 1
#_<proser_gamma>
mixup_layer: [1]
mixup_type: style
batmix_ratio: 1
mix_ratio: 0.5

# stat_type: margin1

# Checkpoints
loss_str: ''
check_path: !ref Data/checkpoint/<model><resnet_size>/<datasets>/<feat_type>_egs<subset>_baseline/<loss>_<optimizer>_<scheduler>/<input_norm>_batch<batch_size>_<block_type>_red<red_ratio>_down<downsample>_avg<avg_size>_<encoder_type>_em<embedding_size>_dp05_alpha<alpha>_<fast>_wde5_var2ses_bashuf2_dist
#  _mani<mixup_layer>_lamda<lamda_beta>
#_mixup<lamda_beta>_<mixup_type>

save_data_dir: !ref Data/checkpoint/<model><resnet_size>/<datasets>/<feat_type>_egs<subset>_baseline/<loss>_<optimizer>_<scheduler>/<input_norm>_batch<batch_size>_<block_type>_red<red_ratio>_down<downsample>_avg<avg_size>_<encoder_type>_em<embedding_size>_dp05_alpha<alpha>_<fast>_wde5_var2ses_bashuf2_dist

resume: ''
#  !ref <check_path>/checkpoint_40.pth

veri_pairs: 9600
gpu_id: 0,1

test_interval: 4
log_interval: 10

# 0         +
# 0 1
# 0 1 2     +
# 0 2       +
# 0 2 3     +
# 1 2 3
# 2 3 4     +
# 3 4 5     +
# 4 5 6     +
# 5 6 7
# 6 7
# 7         +
