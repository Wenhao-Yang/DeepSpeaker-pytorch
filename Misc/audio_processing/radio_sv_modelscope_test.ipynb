{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d608c13-f441-438c-9d63-5890f58f032d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 14:03:49,718 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.2\n",
      "2023-09-09 14:03:50,384 - modelscope - INFO - initiate model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k\n",
      "2023-09-09 14:03:50,385 - modelscope - INFO - initiate model from location /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k.\n",
      "2023-09-09 14:03:50,388 - modelscope - INFO - initialize model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k\n",
      "2023-09-09 14:03:53,155 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-09 14:03:53,158 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-09 14:03:53,159 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k'}. trying to build by task and model information.\n",
      "2023-09-09 14:03:53,160 - modelscope - WARNING - No preprocessor key ('cam++-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fef28-be32-4f9e-9763-66699202529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_pp\n",
    "sv_pipeline = pipeline(\n",
    "    task=Tasks.speaker_verification,\n",
    "    model='damo/speech_campplus_sv_en_voxceleb_16k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72290a7b-e84b-4418-80b8-c3ab159cd8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 14:42:19,347 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 357/357 [00:00<00:00, 29.8kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79.5M/79.5M [00:00<00:00, 86.6MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79.5k/79.5k [00:00<00:00, 5.10MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 551/551 [00:00<00:00, 284kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 244k/244k [00:00<00:00, 6.30MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 196k/196k [00:00<00:00, 4.93MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 244k/244k [00:00<00:00, 6.42MB/s]\n",
      "2023-09-09 14:42:22,164 - modelscope - INFO - initiate model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_ecapa-tdnn_sv_en_voxceleb_16k\n",
      "2023-09-09 14:42:22,165 - modelscope - INFO - initiate model from location /home/yangwenhao/.cache/modelscope/hub/damo/speech_ecapa-tdnn_sv_en_voxceleb_16k.\n",
      "2023-09-09 14:42:22,168 - modelscope - INFO - initialize model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_ecapa-tdnn_sv_en_voxceleb_16k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 14:42:22,448 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-09 14:42:22,450 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-09 14:42:22,452 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/yangwenhao/.cache/modelscope/hub/damo/speech_ecapa-tdnn_sv_en_voxceleb_16k'}. trying to build by task and model information.\n",
      "2023-09-09 14:42:22,453 - modelscope - WARNING - No preprocessor key ('ecapa-tdnn-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "# ecapa-tdnn\n",
    "sv_pipeline = pipeline(\n",
    "    task='speaker-verification',\n",
    "    model='damo/speech_ecapa-tdnn_sv_en_voxceleb_16k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5706a357-cc44-4f6b-bec8-1de266800781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 12:18:24,769 - modelscope - INFO - PyTorch version 2.0.1 Found.\n",
      "2023-09-11 12:18:24,771 - modelscope - INFO - Loading ast index from /home/yangwenhao/.cache/modelscope/ast_indexer\n",
      "2023-09-11 12:18:24,962 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 2fd7920946625a585615c128019784ec and a total number of 921 components indexed\n",
      "/home/yangwenhao/anaconda3/envs/model/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-11 12:18:25,883 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.7M/26.7M [01:55<00:00, 242kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 389/389 [00:00<00:00, 128kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.90k/4.90k [00:00<00:00, 1.46MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116k/116k [00:00<00:00, 5.22MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 153k/153k [00:00<00:00, 5.36MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 166k/166k [00:00<00:00, 353kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 279k/279k [00:01<00:00, 271kB/s]\n",
      "2023-09-11 12:20:25,115 - modelscope - INFO - initiate model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_zh-cn_16k-common\n",
      "2023-09-11 12:20:25,115 - modelscope - INFO - initiate model from location /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_zh-cn_16k-common.\n",
      "2023-09-11 12:20:25,117 - modelscope - INFO - initialize model from /home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_zh-cn_16k-common\n",
      "2023-09-11 12:20:27,733 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-11 12:20:27,735 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-11 12:20:27,735 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/yangwenhao/.cache/modelscope/hub/damo/speech_campplus_sv_zh-cn_16k-common'}. trying to build by task and model information.\n",
      "2023-09-11 12:20:27,736 - modelscope - WARNING - No preprocessor key ('cam++-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "sv_pipeline = pipeline(\n",
    "    task='speaker-verification',\n",
    "    model='damo/speech_campplus_sv_zh-cn_16k-common',\n",
    "    model_revision='v1.0.0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b778d68-ee7f-4e4f-963b-0f9fe8e21267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "from Eval.eval_metrics import evaluate_kaldi_eer, evaluate_kaldi_mindcf\n",
    "\n",
    "def read_hdf5(reader, key):\n",
    "    with h5py.File(reader, 'r') as r:\n",
    "        data_flat = r.get(key)[:]\n",
    "        return data_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9100d1-a09b-404f-989b-5e34c09285f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 14622/14622 [12:50<00:00, 18.97it/s]\n"
     ]
    }
   ],
   "source": [
    "test_subset = 'test_orgchn2band' # 'test_orgchn2'\n",
    "save_dir    = 'radio/data/cam_pp_zh/'\n",
    "wav_scp     = '/home/yangwenhao/project/lstm_speaker_verification/data/vox1/%s/wav.scp'%(test_subset)\n",
    "\n",
    "uid2path = {}\n",
    "emb_file = save_dir + 'xvector.h5py'\n",
    "\n",
    "with  h5py.File(emb_file, 'w') as gf:\n",
    "    with open(wav_scp, 'r') as f:\n",
    "        for l in tqdm(f.readlines(), ncols=50):\n",
    "            uid, upath = l.split()\n",
    "            uid2path[uid] = upath\n",
    "\n",
    "            result = sv_pipeline(in_audios=[upath], output_emb=True)\n",
    "            emb = result[1]\n",
    "\n",
    "            gf.create_dataset(uid, data=emb, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90021470-15c2-44dc-8945-3988e1dccd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_fn = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c272d7e5-a646-48b2-ab41-11251b13714b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 37720/37720 [00:54<00:00, 694.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original    :  EER(%): 7.88  MinDCF: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 37720/37720 [00:52<00:00, 721.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radio       :  EER(%): 21.27  MinDCF: 0.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 75440/75440 [01:45<00:00, 713.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radiocross  :  EER(%): 24.14  MinDCF: 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 37720/37720 [00:52<00:00, 715.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandpass    :  EER(%): 17.62  MinDCF: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 75440/75440 [01:45<00:00, 715.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandcross   :  EER(%): 17.66  MinDCF: 0.9662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████| 75440/75440 [01:45<00:00, 716.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandradio   :  EER(%): 26.63  MinDCF: 0.9773\n"
     ]
    }
   ],
   "source": [
    "# for subs in ['bandpass', 'bandcross', 'bandradio']:\n",
    "for subs in ['original', 'radio', 'radiocross', 'bandpass', 'bandcross', 'bandradio']:\n",
    "    \n",
    "    trials = '/home/yangwenhao/project/lstm_speaker_verification/data/vox1/%s/trials_%s'%(test_subset, subs)\n",
    "    distances = []\n",
    "    labels = []\n",
    "    with open(trials, 'r') as f:\n",
    "        for l in tqdm(f.readlines(), ncols=50):\n",
    "            a,b,target = l.split()\n",
    "            a = torch.tensor(read_hdf5(emb_file, a))\n",
    "            b = torch.tensor(read_hdf5(emb_file, b))\n",
    "            d = dist_fn(a, b)\n",
    "            distances.append(d[0])\n",
    "\n",
    "            if target == 'target':\n",
    "                labels.append(True)\n",
    "            else:\n",
    "                labels.append(False)\n",
    "\n",
    "    eer, eer_threshold, accuracy = evaluate_kaldi_eer(\n",
    "            distances, labels, cos=True, re_thre=True)\n",
    "    mindcf_01, mindcf_001 = evaluate_kaldi_mindcf(distances, labels)\n",
    "\n",
    "    print('{:<12s}:  EER(%): {:.2f}  MinDCF: {:.4f}'.format(subs, eer*100, mindcf_01))\n",
    "    \n",
    "# cam_pp vox2\n",
    "# original    :  EER(%): 0.89  MinDCF: 0.0938\n",
    "# radio       :  EER(%): 2.35  MinDCF: 0.3141\n",
    "# radiocross  :  EER(%): 2.10  MinDCF: 0.2678\n",
    "\n",
    "# ECAPA-TDNN vox2\n",
    "# original    :  EER(%): 1.00  MinDCF: 0.1021\n",
    "# radio       :  EER(%): 2.70  MinDCF: 0.3496\n",
    "# radiocross  :  EER(%): 2.31  MinDCF: 0.3055\n",
    "# bandpass    :  EER(%): 3.05  MinDCF: 0.3696\n",
    "# bandcross   :  EER(%): 2.31  MinDCF: 0.3072\n",
    "# bandradio   :  EER(%): 3.36  MinDCF: 0.4165\n",
    "\n",
    "# cam_pp 3d-zh\n",
    "# original    :  EER(%): 7.88  MinDCF: 0.6422\n",
    "# radio       :  EER(%): 21.27  MinDCF: 0.9945\n",
    "# radiocross  :  EER(%): 24.14  MinDCF: 0.9264\n",
    "# bandpass    :  EER(%): 17.62  MinDCF: 0.8550\n",
    "# bandcross   :  EER(%): 17.66  MinDCF: 0.9662\n",
    "# bandradio   :  EER(%): 26.63  MinDCF: 0.9773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba48fe4-8c70-4ce3-b96c-483ca046ec22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
