{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cff1f60-bea1-4150-bb94-2ea083766915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from Process_Data.Datasets.LmdbDataset import Hdf5DelectDataset\n",
    "import Process_Data.constants as c\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch._utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from kaldi_io import read_mat\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Define_Model.SoftmaxLoss import AngleLinear, AdditiveMarginLinear\n",
    "# from Define_Model.model import PairwiseDistance\n",
    "from Process_Data.Datasets.KaldiDataset import ScriptTrainDataset, \\\n",
    "    ScriptTestDataset, ScriptValidDataset\n",
    "from Process_Data.audio_processing import ConcateOrgInput, mvnormal, ConcateVarInput, read_WaveInt\n",
    "from TrainAndTest.common_func import create_model, load_model_args, args_model, args_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d91de6-d63c-4c02-bf51-9edb2231f54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_outputs_and_gradients(inputs, model, target_label_idx,\n",
    "                                    internal_batch=10):\n",
    "    \"\"\"sumary_line\n",
    "    \n",
    "    Keyword arguments:\n",
    "    internal_batch -- internal batch_size has little effect on saliency mapplings.\n",
    "    Return: return_description\n",
    "    \"\"\"\n",
    "    \n",
    "    # do the pre-processing\n",
    "    \n",
    "    if internal_batch != 1:\n",
    "        inputs = torch.cat(inputs)\n",
    "        real_inputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            if i % internal_batch == 0:\n",
    "                real_inputs.append(inputs[i:(i+internal_batch)])\n",
    "        \n",
    "        inputs = real_inputs\n",
    "\n",
    "    gradients = []\n",
    "    for s in inputs:\n",
    "        s = Variable(s.cuda(), requires_grad=True)\n",
    "\n",
    "        output, _ = model(s)\n",
    "        output = F.softmax(output, dim=1)\n",
    "\n",
    "        if target_label_idx is None:\n",
    "            target_label_idx = torch.argmax(output, 1).item()\n",
    "\n",
    "        index = torch.ones((output.size()[0], 1)) * target_label_idx\n",
    "        index = torch.tensor(index, dtype=torch.int64)\n",
    "        if s.is_cuda:\n",
    "            index = index.cuda()\n",
    "\n",
    "        output = output.gather(1, index)\n",
    "        \n",
    "        if internal_batch != 1:\n",
    "            output = output.sum()\n",
    "\n",
    "        # clear grad\n",
    "        model.zero_grad()\n",
    "        output.backward()\n",
    "\n",
    "        gradient = s.grad.detach()#.cpu()\n",
    "        gradients.append(gradient)\n",
    "\n",
    "    gradients = torch.cat(gradients)\n",
    "\n",
    "    return gradients, target_label_idx\n",
    "\n",
    "\n",
    "def padding_baselines(data, baselines):\n",
    "    this_baselinses = []\n",
    "    for the_data in baselines:\n",
    "        while the_data.shape[1] < data.shape[-2]:\n",
    "            the_data = np.concatenate([the_data, the_data], axis=1)\n",
    "        \n",
    "        the_data = torch.tensor(the_data[:, :data.shape[-2]]).float().unsqueeze(0)\n",
    "        this_baselinses.append(the_data)\n",
    "        \n",
    "    return torch.cat(this_baselinses, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d50a71b-7053-4753-8e4a-6f7775081083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_path = '/home/yangwenhao/project/lstm_speaker_verification'\n",
    "root_dir = '/home/yangwenhao/local/project/SpeakerVerification-pytorch'\n",
    "gradient_path = root_dir + '/Data/gradient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e8ed9-d87f-4eef-9b10-12356657dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_method = 'integrad2' #   fullgrad grad_cam_pp integrad layer_cam\n",
    "model_path = 'ThinResNet18/Mean_batch128_k7_seblock_downk1_avg1_SAP2_em256_dp01_alpha0_none1_wd5e5_varesmix8/arcsoft_sgd_rop/vox2/wave_fb80_dist2/123456'\n",
    "train_set = 'vox2'\n",
    "epoch = 25\n",
    "check_yaml = root_dir + '/Data/checkpoint/{}/model.2023.08.02.yaml'.format(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
