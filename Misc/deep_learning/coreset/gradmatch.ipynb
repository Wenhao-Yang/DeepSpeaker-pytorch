{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0206358a-de5f-4d48-b9b7-fc32e180e166",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6489aebd-486c-45f0-8cbb-dd4f66482db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssd2020/yangwenhao/conda/env/cords/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-19 13:00:28,501\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-19 13:00:28,562\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from cords.utils.data.datasets.SL import gen_dataset\n",
    "from torch.utils.data import Subset\n",
    "from cords.utils.config_utils import load_config_data\n",
    "import os.path as osp\n",
    "from cords.utils.data.data_utils import WeightedSubset\n",
    "from ray import tune\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000364f3-0870-48fa-b72c-be483005a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Light.dataset import Sampler_Loaders, SubDatasets, SubScriptDatasets, SubLoaders\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from Light.model import SpeakerLoss\n",
    "from Define_Model.Optimizer import EarlyStopping\n",
    "\n",
    "from TrainAndTest.common_func import create_classifier, create_optimizer, create_scheduler, create_model, verification_test, verification_extract, \\\n",
    "    args_parse, args_model, save_model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f08dc32-b05f-4455-951c-a47c9b0fb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6425c8c0-36c9-4dfc-bf1c-2ec0892141e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/yangwenhao/project/SpeakerVerification-pytorch'\n",
    "lstm_dir = '/home/yangwenhao/project/lstm_speaker_verification/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd06547-59ee-4919-b72a-05244e2ab9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_config = data_dir + '/Data/checkpoint/ECAPA_brain/Mean_batch96_SASP2_em192_official_2sesmix8/arcsoft_adam_cyclic/vox1/wave_fb80_band05_aug5/123456/model.2023.12.17.yaml'\n",
    "\n",
    "train_config = 'model.2023.12.17.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d6cbd9-4e0e-466b-ba09-6b93446450d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6396e7b9-961f-421d-8111-bf5b4279b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_config, 'r') as f:\n",
    "        config_args = load_hyperpyyaml(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c1a7a-bbad-4daf-853f-9c76060ed57b",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468325e9-cd0c-4310-9db1-b15136d6613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating 1 lengths with Average: 32000.\n"
     ]
    }
   ],
   "source": [
    "train_dir, valid_dir, train_extract_dir = SubScriptDatasets(config_args)\n",
    "# train_loader, train_sampler, valid_loader, valid_sampler, train_extract_loader, train_extract_sampler = Sampler_Loaders(\n",
    "#         train_dir, valid_dir, train_extract_dir, config_args)\n",
    "# train_dir.base_utts = train_dir.base_utts[:153600]\n",
    "train_loader, valid_loader, train_extract_loader = SubLoaders(train_dir, valid_dir, train_extract_dir, config_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b7fc91-bc60-4cc3-8181-151409fa6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' #Device Argument\n",
    "\n",
    "model = config_args['embedding_model']\n",
    "\n",
    "model.loss = SpeakerLoss(config_args)\n",
    "model.loss.reduction = 'none'\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ac529-ad2b-42a0-a945-2dfbfcb5c28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the lr and weight_decay of classifier to 0.001000 and 0.000200\n"
     ]
    }
   ],
   "source": [
    "model_para = [{'params': model.parameters()}]\n",
    "if config_args['loss_type'] in ['center', 'variance', 'mulcenter', 'gaussian', 'coscenter', 'ring']:\n",
    "    assert config_args['lr_ratio'] > 0\n",
    "    model_para.append({'params': model.loss.xe_criterion.parameters(\n",
    "    ), 'lr': config_args['lr'] * config_args['lr_ratio']})\n",
    "\n",
    "if 'second_wd' in config_args and config_args['second_wd'] > 0:\n",
    "    # if config_args['loss_type in ['asoft', 'amsoft']:\n",
    "    classifier_params = list(map(id, model.classifier.parameters()))\n",
    "    rest_params = filter(lambda p: id(\n",
    "        p) not in classifier_params, model.parameters())\n",
    "\n",
    "    init_lr = config_args['lr'] * \\\n",
    "        config_args['lr_ratio'] if config_args['lr_ratio'] > 0 else config_args['lr']\n",
    "    init_wd = config_args['second_wd'] if config_args['second_wd'] > 0 else config_args['weight_decay']\n",
    "    print('Set the lr and weight_decay of classifier to %f and %f' %\n",
    "          (init_lr, init_wd))\n",
    "    model_para = [{'params': rest_params},\n",
    "                  {'params': model.classifier.parameters(), 'lr': init_lr, 'weight_decay': init_wd}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b70344-07ab-464e-8db8-bbe95822f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_kwargs = {'lr': config_args['lr'], 'lr_decay': config_args['lr_decay'],\n",
    "                  'weight_decay': config_args['weight_decay'],\n",
    "                  'dampening': config_args['dampening'],\n",
    "                  'momentum': config_args['momentum'],\n",
    "                  'nesterov': config_args['nesterov']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ddd2f9-3a0b-4388-8ae0-bb181d0dd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = config_args['coreset_percent']\n",
    "optimizer = create_optimizer(\n",
    "        model_para, config_args['optimizer'], **opt_kwargs)\n",
    "scheduler = create_scheduler(optimizer, config_args, train_dir)\n",
    "early_stopping_scheduler = EarlyStopping(patience=config_args['early_patience'],\n",
    "                                             min_delta=config_args['early_delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbf666a-9d55-4c65-bb49-5a4bad7e202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_logger(results_dir):\n",
    "  os.makedirs(results_dir, exist_ok=True)\n",
    "  # setup logger\n",
    "  plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
    "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
    "  logger = logging.getLogger(__name__)\n",
    "  logger.setLevel(logging.INFO)\n",
    "  s_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "  s_handler.setFormatter(plain_formatter)\n",
    "  s_handler.setLevel(logging.INFO)\n",
    "  logger.addHandler(s_handler)\n",
    "  f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
    "  f_handler.setFormatter(plain_formatter)\n",
    "  f_handler.setLevel(logging.DEBUG)\n",
    "  logger.addHandler(f_handler)\n",
    "  logger.propagate = False\n",
    "  return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dcfde1c-3909-4386-8806-0cb4922ea33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:00:32] __main__ INFO: hello\n"
     ]
    }
   ],
   "source": [
    "#Results logging directory\n",
    "results_dir = osp.abspath(osp.expanduser('results_gradmatch_{:.2f}'.format(fraction)))\n",
    "logger = __get_logger(results_dir)\n",
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbe78fca-286c-4482-8ed3-f7ac8a2bb133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cords.utils.data.dataloader.SL.adaptive import GLISTERDataLoader, GradMatchDataLoader\n",
    "\n",
    "#, OLRandomDataLoader, \\\n",
    "    # CRAIGDataLoader, GradMatchDataLoader, RandomDataLoader\n",
    "from dotmap import DotMap\n",
    "\n",
    "selection_strategy = 'GLISTER'\n",
    "# dss_args = dict(model=model,\n",
    "#                 loss=model.loss,\n",
    "#                 eta=0.01,\n",
    "#                 num_classes=1211,\n",
    "#                 num_epochs=30,\n",
    "#                 device='cuda',\n",
    "#                 fraction=0.25,\n",
    "#                 select_every=6,\n",
    "#                 kappa=0,\n",
    "#                 linear_layer=False,\n",
    "#                 selection_type='SL',\n",
    "#                 greedy='Stochastic')\n",
    "\n",
    "dss_args=dict(type=\"GradMatch\",\n",
    "                            fraction=fraction,\n",
    "                            select_every=6,\n",
    "                            lam=0.5,\n",
    "                            selection_type='PerBatch',\n",
    "                            v1=True,\n",
    "                            valid=False,\n",
    "                            kappa=0,\n",
    "                            eps=1e-100,\n",
    "                            linear_layer=False,\n",
    "                            model=model,\n",
    "                            loss=model.loss,\n",
    "                            eta = 0.001,\n",
    "                            num_classes = 1211,\n",
    "                            device = 'cuda'\n",
    "                            )\n",
    "\n",
    "dss_args = DotMap(dss_args)\n",
    "\n",
    "# dataloader = GLISTERDataLoader(train_loader, valid_loader, dss_args, logger, \n",
    "#                                   batch_size=config_args['batch_size'], \n",
    "#                                   shuffle=True,\n",
    "#                                   pin_memory=False)\n",
    "dataloader = GradMatchDataLoader(train_loader, valid_loader, dss_args, logger, \n",
    "                                  batch_size=config_args['batch_size'], \n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c57f77b6-3f6a-4f57-bf88-7bf18ac5b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Arguments\n",
    "num_epochs = 30\n",
    "\n",
    "#Arguments for results logging\n",
    "print_every = 1\n",
    "# print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
    "print_args = [\"val_loss\", \"val_acc\", \"time\"]\n",
    "\n",
    "#Argumets for checkpointing\n",
    "save_every = 3\n",
    "is_save = True\n",
    "\n",
    "#Evaluation Metrics\n",
    "trn_losses = list()\n",
    "val_losses = list()\n",
    "tst_losses = list()\n",
    "subtrn_losses = list()\n",
    "timing = list()\n",
    "trn_acc = list()\n",
    "val_acc = list()  \n",
    "tst_acc = list()  \n",
    "subtrn_acc = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91b3b02-5e7b-4a78-aca8-b10e62aa10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cumulative_timing(mod_timing):\n",
    "    tmp = 0\n",
    "    mod_cum_timing = np.zeros(len(mod_timing))\n",
    "    for i in range(len(mod_timing)):\n",
    "         mod_cum_timing[i] = tmp\n",
    "    return mod_cum_timing / 3600\n",
    "\n",
    "def save_ckpt(state, ckpt_path):\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_ckpt(ckpt_path, model, optimizer):\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    loss = checkpoint['loss']\n",
    "    metrics = checkpoint['metrics']\n",
    "    return start_epoch, model, optimizer, loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe76945-7e49-4aad-be74-c3e138c31acd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216e7fd-3d51-4e4d-af8f-ba0d3653c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [04:56,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:05:42] __main__ INFO: Epoch: 1 , Valid Loss: 5626.20306540 , Valid Accuracy: 0.1685 , Timing: 296.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:02,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:10:59] __main__ INFO: Epoch: 2 , Valid Loss: 3937.11729550 , Valid Accuracy: 0.4898 , Timing: 302.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:02,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:16:17] __main__ INFO: Epoch: 3 , Valid Loss: 3255.43047476 , Valid Accuracy: 0.6129 , Timing: 302.61\n",
      "[12/19 13:16:17] __main__ INFO: Model checkpoint saved at epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:08,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:21:40] __main__ INFO: Epoch: 4 , Valid Loss: 2717.97639334 , Valid Accuracy: 0.7111 , Timing: 308.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:10,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:27:05] __main__ INFO: Epoch: 5 , Valid Loss: 2496.75148737 , Valid Accuracy: 0.7521 , Timing: 310.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:07,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:32:29] __main__ INFO: Epoch: 6 , Valid Loss: 2363.78641975 , Valid Accuracy: 0.7734 , Timing: 307.96\n",
      "[12/19 13:32:29] __main__ INFO: Model checkpoint saved at epoch: 6\n",
      "[12/19 13:38:42] __main__ INFO: Epoch: 6, GradMatch subset selection finished, takes 372.6162. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:13,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:44:11] __main__ INFO: Epoch: 7 , Valid Loss: 2316.30498886 , Valid Accuracy: 0.7808 , Timing: 686.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:02,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:49:28] __main__ INFO: Epoch: 8 , Valid Loss: 2348.31693327 , Valid Accuracy: 0.7773 , Timing: 302.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [04:59,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:54:41] __main__ INFO: Epoch: 9 , Valid Loss: 2416.97869110 , Valid Accuracy: 0.7651 , Timing: 299.05\n",
      "[12/19 13:54:41] __main__ INFO: Model checkpoint saved at epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [04:57,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 13:59:53] __main__ INFO: Epoch: 10 , Valid Loss: 2275.25186282 , Valid Accuracy: 0.7868 , Timing: 297.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [04:58,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:05:06] __main__ INFO: Epoch: 11 , Valid Loss: 2226.53002775 , Valid Accuracy: 0.7927 , Timing: 298.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [04:57,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:10:18] __main__ INFO: Epoch: 12 , Valid Loss: 2179.82601267 , Valid Accuracy: 0.8009 , Timing: 297.92\n",
      "[12/19 14:10:18] __main__ INFO: Model checkpoint saved at epoch: 12\n",
      "[12/19 14:16:38] __main__ INFO: Epoch: 12, GradMatch subset selection finished, takes 380.1533. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:16,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:22:11] __main__ INFO: Epoch: 13 , Valid Loss: 2096.02711248 , Valid Accuracy: 0.8130 , Timing: 697.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:10,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:27:36] __main__ INFO: Epoch: 14 , Valid Loss: 2094.81016183 , Valid Accuracy: 0.8152 , Timing: 310.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:03,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:32:55] __main__ INFO: Epoch: 15 , Valid Loss: 2144.06909168 , Valid Accuracy: 0.8073 , Timing: 303.48\n",
      "[12/19 14:32:55] __main__ INFO: Model checkpoint saved at epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:08,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:38:19] __main__ INFO: Epoch: 16 , Valid Loss: 2104.36003518 , Valid Accuracy: 0.8119 , Timing: 308.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:03,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:43:37] __main__ INFO: Epoch: 17 , Valid Loss: 2080.10054201 , Valid Accuracy: 0.8162 , Timing: 303.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:07,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 14:48:59] __main__ INFO: Epoch: 18 , Valid Loss: 2065.94685805 , Valid Accuracy: 0.8218 , Timing: 307.13\n",
      "[12/19 14:48:59] __main__ INFO: Model checkpoint saved at epoch: 18\n",
      "[12/19 14:55:35] __main__ INFO: Epoch: 18, GradMatch subset selection finished, takes 396.1364. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [05:13,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/19 15:01:04] __main__ INFO: Epoch: 19 , Valid Loss: 2016.39398140 , Valid Accuracy: 0.8243 , Timing: 709.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721it [03:54,  3.25it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "################################################# Training Loop #################################################\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    subtrn_loss = 0\n",
    "    subtrn_correct = 0\n",
    "    subtrn_total = 0\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for _, (inputs, targets, weights) in tqdm(enumerate(dataloader), ncols=50):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        weights = weights.to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, feats = model(inputs)\n",
    "        losses  = model.loss((outputs, feats), targets)\n",
    "        loss = torch.dot(losses, weights/(weights.sum()))\n",
    "        loss.backward()\n",
    "        \n",
    "        subtrn_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        _, predicted = outputs.max(1)\n",
    "        subtrn_total += targets.size(0)\n",
    "        subtrn_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    epoch_time = time.time() - start_time\n",
    "    timing.append(epoch_time)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ################################################# Evaluation Loop #################################################\n",
    "    \"\"\"\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        trn_loss, trn_correct, trn_total = 0, 0, 0\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        tst_correct, tst_total, tst_loss = 0, 0, 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    \n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    trn_loss += loss.item()\n",
    "                    if \"trn_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        trn_total += targets.size(0)\n",
    "                        trn_correct += predicted.eq(targets).sum().item()\n",
    "                        \n",
    "                trn_losses.append(trn_loss)\n",
    "\n",
    "            if \"trn_acc\" in print_args:\n",
    "                trn_acc.append(trn_correct / trn_total)\n",
    "\n",
    "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    # outputs = model(inputs)\n",
    "                    # loss = criterion(outputs, targets)\n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    val_loss += loss.mean().item()\n",
    "                    if \"val_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_total += targets.size(0)\n",
    "                        val_correct += predicted.eq(targets).sum().item()\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            if \"val_acc\" in print_args:\n",
    "                val_acc.append(val_correct / val_total)\n",
    "\n",
    "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    \n",
    "                    # outputs = model(inputs)\n",
    "                    # loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    tst_loss += loss.mean().item()\n",
    "                    if \"tst_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        tst_total += targets.size(0)\n",
    "                        tst_correct += predicted.eq(targets).sum().item()\n",
    "                tst_losses.append(tst_loss)\n",
    "\n",
    "            if \"tst_acc\" in print_args:\n",
    "                tst_acc.append(tst_correct / tst_total)\n",
    "\n",
    "        if \"subtrn_acc\" in print_args:\n",
    "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
    "\n",
    "        if \"subtrn_losses\" in print_args:\n",
    "            subtrn_losses.append(subtrn_loss)\n",
    "\n",
    "        print_str = \"Epoch: \" + str(epoch + 1)\n",
    "\n",
    "        \"\"\"\n",
    "        ################################################# Results Printing #################################################\n",
    "        \"\"\"\n",
    "\n",
    "        for arg in print_args:\n",
    "\n",
    "            if arg == \"val_loss\":\n",
    "                print_str += \" , \" + \"Valid Loss: {:.8f}\".format(val_losses[-1])\n",
    "\n",
    "            if arg == \"val_acc\":\n",
    "                print_str += \" , \" + \"Valid Accuracy: {:.4f}\".format(val_acc[-1])\n",
    "\n",
    "            if arg == \"tst_loss\":\n",
    "                print_str += \" , \" + \"Test Loss: {:.8f}\".format(tst_losses[-1])\n",
    "\n",
    "            if arg == \"tst_acc\":\n",
    "                print_str += \" , \" + \"Test Accuracy: {:.4f}\".format(tst_acc[-1])\n",
    "\n",
    "            if arg == \"trn_loss\":\n",
    "                print_str += \" , \" + \"Train Loss: {:.8f}\".format(trn_losses[-1])\n",
    "\n",
    "            if arg == \"trn_acc\":\n",
    "                print_str += \" , \" + \"Train Accuracy: {:.4f}\".format(trn_acc[-1])\n",
    "\n",
    "            if arg == \"subtrn_loss\":\n",
    "                print_str += \" , \" + \"Subset Loss: {:.8f}\".format(subtrn_losses[-1])\n",
    "\n",
    "            if arg == \"subtrn_acc\":\n",
    "                print_str += \" , \" + \"Subset Accuracy: {:.4f}\".format(subtrn_acc[-1])\n",
    "\n",
    "            if arg == \"time\":\n",
    "                print_str += \" , \" + \"Timing: {:.2f}\".format(timing[-1])\n",
    "\n",
    "        logger.info(print_str)\n",
    "\n",
    "    \"\"\"\n",
    "    ################################################# Checkpoint Saving #################################################\n",
    "    \"\"\"\n",
    "\n",
    "    if ((epoch + 1) % save_every == 0) and is_save:\n",
    "\n",
    "        metric_dict = {}\n",
    "\n",
    "        for arg in print_args:\n",
    "            if arg == \"val_loss\":\n",
    "                metric_dict['val_loss'] = val_losses\n",
    "            if arg == \"val_acc\":\n",
    "                metric_dict['val_acc'] = val_acc\n",
    "            if arg == \"tst_loss\":\n",
    "                metric_dict['tst_loss'] = tst_losses\n",
    "            if arg == \"tst_acc\":\n",
    "                metric_dict['tst_acc'] = tst_acc\n",
    "            if arg == \"trn_loss\":\n",
    "                metric_dict['trn_loss'] = trn_losses\n",
    "            if arg == \"trn_acc\":\n",
    "                metric_dict['trn_acc'] = trn_acc\n",
    "            if arg == \"subtrn_loss\":\n",
    "                metric_dict['subtrn_loss'] = subtrn_losses\n",
    "            if arg == \"subtrn_acc\":\n",
    "                metric_dict['subtrn_acc'] = subtrn_acc\n",
    "            if arg == \"time\":\n",
    "                metric_dict['time'] = timing\n",
    "\n",
    "        ckpt_state = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': model.loss,\n",
    "            'metrics': metric_dict\n",
    "        }\n",
    "\n",
    "        # save checkpoint\n",
    "        save_ckpt(ckpt_state, 'model.pt')\n",
    "        logger.info(\"Model checkpoint saved at epoch: {0:d}\".format(epoch + 1))\n",
    "\n",
    "\"\"\"\n",
    "################################################# Results Summary #################################################\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"{0:s} Selection Run---------------------------------\".format(selection_strategy))\n",
    "logger.info(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
    "if \"val_loss\" in print_args:\n",
    "    if \"val_acc\" in print_args:\n",
    "        logger.info(\"Valid Loss: %.2f , Validation Accuracy: %.2f\", val_loss, val_acc[-1])\n",
    "    else:\n",
    "        logger.info(\"Valid Loss: %.2f\", val_loss)\n",
    "\n",
    "if \"tst_loss\" in print_args:\n",
    "    if \"tst_acc\" in print_args:\n",
    "        logger.info(\"Test Loss: %.2f, Test Accuracy: %.2f\", tst_loss, tst_acc[-1])\n",
    "    else:\n",
    "        logger.info(\"Test Data Loss: %f\", tst_loss)\n",
    "        \n",
    "logger.info('---------------------------------------------------------------------')\n",
    "logger.info(selection_strategy)\n",
    "logger.info('---------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532d25d-5e5e-41d9-90cd-a3cc650484c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "################################################# Final Results Logging #################################################\n",
    "\"\"\"\n",
    "\n",
    "if \"val_acc\" in print_args:\n",
    "    val_str = \"Valid Accuracy, \" + \" , \".join([str(val) for val in val_acc])\n",
    "    logger.info(val_str)\n",
    "\n",
    "if \"tst_acc\" in print_args:\n",
    "    tst_str = \"Test Accuracy, \" + \" , \".join([str(tst) for tst in tst_acc])\n",
    "    logger.info(tst_str)\n",
    "\n",
    "if \"time\" in print_args:\n",
    "    time_str = \"Time, \" + \" , \".join([str(t) for t in timing])\n",
    "    logger.info(timing)\n",
    "\n",
    "timing_array = np.array(timing)\n",
    "cum_timing = list(generate_cumulative_timing(timing_array))\n",
    "logger.info(\"Total time taken by %s = %.4f \", selection_strategy, cum_timing[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d9a92-1b5e-429b-97a5-5fa7aa9f5ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cords",
   "language": "python",
   "name": "cords"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
