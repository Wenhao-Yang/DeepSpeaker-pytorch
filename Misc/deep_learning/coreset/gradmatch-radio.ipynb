{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0206358a-de5f-4d48-b9b7-fc32e180e166",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6489aebd-486c-45f0-8cbb-dd4f66482db2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangwenhao/anaconda3/envs/cords/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-22 14:36:48,637\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-22 14:36:48,948\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from cords.utils.data.datasets.SL import gen_dataset\n",
    "from torch.utils.data import Subset\n",
    "from cords.utils.config_utils import load_config_data\n",
    "from cords.utils.data.data_utils import WeightedSubset\n",
    "from ray import tune\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os.path as osp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000364f3-0870-48fa-b72c-be483005a55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Light.dataset import Sampler_Loaders, SubDatasets, SubScriptDatasets, SubLoaders\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from Light.model import SpeakerLoss\n",
    "from Define_Model.Optimizer import EarlyStopping\n",
    "\n",
    "from TrainAndTest.common_func import create_classifier, create_optimizer, create_scheduler, create_model, verification_test, verification_extract, \\\n",
    "    args_parse, args_model, save_model_args\n",
    "\n",
    "from cords.utils.data.dataloader.SL.adaptive import GLISTERDataLoader, GradMatchDataLoader\n",
    "\n",
    "#, OLRandomDataLoader, \\\n",
    "    # CRAIGDataLoader, GradMatchDataLoader, RandomDataLoader\n",
    "from dotmap import DotMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a5721a-b4d0-438c-8ace-737ebb9a8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_logger(results_dir):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # setup logger\n",
    "    plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
    "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    s_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    s_handler.setFormatter(plain_formatter)\n",
    "    s_handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(s_handler)\n",
    "    f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
    "    f_handler.setFormatter(plain_formatter)\n",
    "    f_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(f_handler)\n",
    "    logger.propagate = False\n",
    "    return logger\n",
    "\n",
    "def generate_cumulative_timing(mod_timing):\n",
    "    tmp = 0\n",
    "    mod_cum_timing = np.zeros(len(mod_timing))\n",
    "    for i in range(len(mod_timing)):\n",
    "         mod_cum_timing[i] = tmp\n",
    "    return mod_cum_timing / 3600\n",
    "\n",
    "def save_ckpt(state, ckpt_path):\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_ckpt(ckpt_path, model, optimizer):\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    loss = checkpoint['loss']\n",
    "    metrics = checkpoint['metrics']\n",
    "    return start_epoch, model, optimizer, loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08dc32-b05f-4455-951c-a47c9b0fb60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6425c8c0-36c9-4dfc-bf1c-2ec0892141e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/yangwenhao/project/SpeakerVerification-pytorch'\n",
    "lstm_dir = '/home/yangwenhao/project/lstm_speaker_verification/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d6cbd9-4e0e-466b-ba09-6b93446450d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6396e7b9-961f-421d-8111-bf5b4279b48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_config = data_dir + '/Data/checkpoint/ECAPA_brain/Mean_batch96_SASP2_em192_official_2sesmix8/arcsoft_adam_cyclic/vox1/wave_fb80_band05_aug5/123456/model.2023.12.17.yaml'\n",
    "\n",
    "train_config = 'model-radio-2023.12.17.yaml'\n",
    "\n",
    "with open(train_config, 'r') as f:\n",
    "    config_args = load_hyperpyyaml(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c1a7a-bbad-4daf-853f-9c76060ed57b",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468325e9-cd0c-4310-9db1-b15136d6613f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating 1 lengths with Average: 32000.\n"
     ]
    }
   ],
   "source": [
    "train_dir, valid_dir, train_extract_dir = SubScriptDatasets(config_args)\n",
    "# train_loader, train_sampler, valid_loader, valid_sampler, train_extract_loader, train_extract_sampler = Sampler_Loaders(\n",
    "#         train_dir, valid_dir, train_extract_dir, config_args)\n",
    "# train_dir.base_utts = train_dir.base_utts[:153600]\n",
    "train_loader, valid_loader, train_extract_loader = SubLoaders(train_dir, valid_dir, train_extract_dir, config_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b7fc91-bc60-4cc3-8181-151409fa6991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:3' #Device Argument\n",
    "\n",
    "model = config_args['embedding_model']\n",
    "\n",
    "model.loss = SpeakerLoss(config_args)\n",
    "model.loss.reduction = 'none'\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ac529-ad2b-42a0-a945-2dfbfcb5c28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the lr and weight_decay of classifier to 0.001000 and 0.000200\n"
     ]
    }
   ],
   "source": [
    "model_para = [{'params': model.parameters()}]\n",
    "if config_args['loss_type'] in ['center', 'variance', 'mulcenter', 'gaussian', 'coscenter', 'ring']:\n",
    "    assert config_args['lr_ratio'] > 0\n",
    "    model_para.append({'params': model.loss.xe_criterion.parameters(\n",
    "    ), 'lr': config_args['lr'] * config_args['lr_ratio']})\n",
    "\n",
    "if 'second_wd' in config_args and config_args['second_wd'] > 0:\n",
    "    # if config_args['loss_type in ['asoft', 'amsoft']:\n",
    "    classifier_params = list(map(id, model.classifier.parameters()))\n",
    "    rest_params = filter(lambda p: id(\n",
    "        p) not in classifier_params, model.parameters())\n",
    "\n",
    "    init_lr = config_args['lr'] * \\\n",
    "        config_args['lr_ratio'] if config_args['lr_ratio'] > 0 else config_args['lr']\n",
    "    init_wd = config_args['second_wd'] if config_args['second_wd'] > 0 else config_args['weight_decay']\n",
    "    print('Set the lr and weight_decay of classifier to %f and %f' %\n",
    "          (init_lr, init_wd))\n",
    "    model_para = [{'params': rest_params},\n",
    "                  {'params': model.classifier.parameters(), 'lr': init_lr, 'weight_decay': init_wd}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ddd2f9-3a0b-4388-8ae0-bb181d0dd2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fraction = config_args['coreset_percent']\n",
    "\n",
    "opt_kwargs = {'lr': config_args['lr'], 'lr_decay': config_args['lr_decay'],\n",
    "                  'weight_decay': config_args['weight_decay'],\n",
    "                  'dampening': config_args['dampening'],\n",
    "                  'momentum': config_args['momentum'],\n",
    "                  'nesterov': config_args['nesterov']}\n",
    "\n",
    "optimizer = create_optimizer(\n",
    "        model_para, config_args['optimizer'], **opt_kwargs)\n",
    "scheduler = create_scheduler(optimizer, config_args, train_dir)\n",
    "early_stopping_scheduler = EarlyStopping(patience=config_args['early_patience'],\n",
    "                                         min_delta=config_args['early_delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcfde1c-3909-4386-8806-0cb4922ea33e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 14:37:06] __main__ INFO: hello\n"
     ]
    }
   ],
   "source": [
    "#Results logging directory\n",
    "result_dname = 'results_radio_gradmatch_{:.2f}_batch{}'.format(fraction, config_args['batch_size'])\n",
    "\n",
    "if 'num_pipes' in config_args:\n",
    "    result_dname += '_aug{}'.format(config_args['num_pipes'])\n",
    "    \n",
    "results_dir = osp.abspath(osp.expanduser(result_dname))\n",
    "logger = __get_logger(results_dir)\n",
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe78fca-286c-4482-8ed3-f7ac8a2bb133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection_strategy = 'GLISTER'\n",
    "# dss_args = dict(model=model,\n",
    "#                 loss=model.loss,\n",
    "#                 eta=0.01,\n",
    "#                 num_classes=1211,\n",
    "#                 num_epochs=30,\n",
    "#                 device='cuda',\n",
    "#                 fraction=0.25,\n",
    "#                 select_every=6,\n",
    "#                 kappa=0,\n",
    "#                 linear_layer=False,\n",
    "#                 selection_type='SL',\n",
    "#                 greedy='Stochastic')\n",
    "\n",
    "dss_args=dict(type=\"GradMatch\",\n",
    "                            fraction=fraction,\n",
    "                            select_every=6,\n",
    "                            lam=0.5,\n",
    "                            selection_type='PerBatch',\n",
    "                            v1=True,\n",
    "                            valid=False,\n",
    "                            kappa=0,\n",
    "                            eps=1e-100,\n",
    "                            linear_layer=False,\n",
    "                            model=model,\n",
    "                            loss=model.loss,\n",
    "                            eta = 0.001,\n",
    "                            num_classes = 1211,\n",
    "                            device = 'cuda'\n",
    "                            )\n",
    "\n",
    "dss_args = DotMap(dss_args)\n",
    "# dataloader = GLISTERDataLoader(train_loader, valid_loader, dss_args, logger, \n",
    "#                                   batch_size=config_args['batch_size'], \n",
    "#                                   shuffle=True,\n",
    "#                                   pin_memory=False)\n",
    "dataloader = GradMatchDataLoader(train_loader, valid_loader, dss_args, logger, \n",
    "                                  batch_size=config_args['batch_size'], \n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57f77b6-3f6a-4f57-bf88-7bf18ac5b3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training Arguments\n",
    "num_epochs = 30\n",
    "\n",
    "#Arguments for results logging\n",
    "print_every = 1\n",
    "# print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
    "print_args = [\"val_loss\", \"val_acc\", \"time\"]\n",
    "\n",
    "#Argumets for checkpointing\n",
    "save_every = 3\n",
    "is_save = True\n",
    "\n",
    "#Evaluation Metrics\n",
    "trn_losses = list()\n",
    "val_losses = list()\n",
    "tst_losses = list()\n",
    "subtrn_losses = list()\n",
    "timing = list()\n",
    "trn_acc = list()\n",
    "val_acc = list()  \n",
    "tst_acc = list()  \n",
    "subtrn_acc = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe76945-7e49-4aad-be74-c3e138c31acd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7363f6cf-3c33-4997-ba00-e5d6e758e012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'augment_pipeline' in config_args:\n",
    "    num_pipes = config_args['num_pipes'] if 'num_pipes' in config_args else 1\n",
    "    augment_pipeline = []\n",
    "    for _, augment in enumerate(config_args['augment_pipeline']):\n",
    "        augment_pipeline.append(augment.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2216e7fd-3d51-4e4d-af8f-ba0d3653c780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:54,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 15:41:15] __main__ INFO: Epoch: 1 , Valid Loss: 1234.73028827 , Valid Accuracy: 0.5465 , Timing: 3834.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:04:39,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 16:46:08] __main__ INFO: Epoch: 2 , Valid Loss: 919.50029731 , Valid Accuracy: 0.7178 , Timing: 3879.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:04:54,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 17:51:17] __main__ INFO: Epoch: 3 , Valid Loss: 818.66325951 , Valid Accuracy: 0.7645 , Timing: 3895.01\n",
      "[12/22 17:51:17] __main__ INFO: Model checkpoint saved at epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:04:58,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 18:56:30] __main__ INFO: Epoch: 4 , Valid Loss: 680.56384981 , Valid Accuracy: 0.8303 , Timing: 3898.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:05:28,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 20:02:13] __main__ INFO: Epoch: 5 , Valid Loss: 601.00488639 , Valid Accuracy: 0.8689 , Timing: 3928.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:05:16,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 21:07:44] __main__ INFO: Epoch: 6 , Valid Loss: 539.34605825 , Valid Accuracy: 0.8864 , Timing: 3916.98\n",
      "[12/22 21:07:44] __main__ INFO: Model checkpoint saved at epoch: 6\n",
      "[12/22 21:47:44] __main__ INFO: Epoch: 6, GradMatch subset selection finished, takes 2400.6877. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:05:16,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 22:53:15] __main__ INFO: Epoch: 7 , Valid Loss: 556.03172994 , Valid Accuracy: 0.8837 , Timing: 6317.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:05:27,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22 23:58:57] __main__ INFO: Epoch: 8 , Valid Loss: 577.92944038 , Valid Accuracy: 0.8717 , Timing: 3927.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:02:50,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 01:02:01] __main__ INFO: Epoch: 9 , Valid Loss: 595.20070076 , Valid Accuracy: 0.8657 , Timing: 3770.27\n",
      "[12/23 01:02:01] __main__ INFO: Model checkpoint saved at epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:02,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 02:05:17] __main__ INFO: Epoch: 10 , Valid Loss: 556.97963166 , Valid Accuracy: 0.8805 , Timing: 3782.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:14,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 03:08:46] __main__ INFO: Epoch: 11 , Valid Loss: 523.51140606 , Valid Accuracy: 0.8895 , Timing: 3794.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:08,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 04:12:09] __main__ INFO: Epoch: 12 , Valid Loss: 483.62164462 , Valid Accuracy: 0.9066 , Timing: 3788.99\n",
      "[12/23 04:12:09] __main__ INFO: Model checkpoint saved at epoch: 12\n",
      "[12/23 04:51:20] __main__ INFO: Epoch: 12, GradMatch subset selection finished, takes 2351.1466. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:02:31,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 05:54:06] __main__ INFO: Epoch: 13 , Valid Loss: 498.73731196 , Valid Accuracy: 0.9041 , Timing: 6102.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:02:28,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 06:56:48] __main__ INFO: Epoch: 14 , Valid Loss: 505.95834744 , Valid Accuracy: 0.8974 , Timing: 3748.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:02:34,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 07:59:37] __main__ INFO: Epoch: 15 , Valid Loss: 523.35722661 , Valid Accuracy: 0.8957 , Timing: 3754.76\n",
      "[12/23 07:59:37] __main__ INFO: Model checkpoint saved at epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:12,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 09:03:03] __main__ INFO: Epoch: 16 , Valid Loss: 505.48717779 , Valid Accuracy: 0.8990 , Timing: 3792.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:03,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 10:06:21] __main__ INFO: Epoch: 17 , Valid Loss: 483.52632463 , Valid Accuracy: 0.9058 , Timing: 3783.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:16,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 11:09:51] __main__ INFO: Epoch: 18 , Valid Loss: 474.82040048 , Valid Accuracy: 0.9095 , Timing: 3796.24\n",
      "[12/23 11:09:51] __main__ INFO: Model checkpoint saved at epoch: 18\n",
      "[12/23 11:49:09] __main__ INFO: Epoch: 18, GradMatch subset selection finished, takes 2357.1630. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:09,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 12:52:33] __main__ INFO: Epoch: 19 , Valid Loss: 469.86846918 , Valid Accuracy: 0.9080 , Timing: 6147.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:20,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 13:56:08] __main__ INFO: Epoch: 20 , Valid Loss: 482.05872703 , Valid Accuracy: 0.9044 , Timing: 3800.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:08,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 14:59:31] __main__ INFO: Epoch: 21 , Valid Loss: 488.41567433 , Valid Accuracy: 0.9061 , Timing: 3788.80\n",
      "[12/23 14:59:31] __main__ INFO: Model checkpoint saved at epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:12,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 16:02:57] __main__ INFO: Epoch: 22 , Valid Loss: 474.16420346 , Valid Accuracy: 0.9122 , Timing: 3792.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:09,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 17:06:21] __main__ INFO: Epoch: 23 , Valid Loss: 468.39774549 , Valid Accuracy: 0.9106 , Timing: 3789.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:07,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 18:09:42] __main__ INFO: Epoch: 24 , Valid Loss: 468.64773375 , Valid Accuracy: 0.9104 , Timing: 3787.60\n",
      "[12/23 18:09:42] __main__ INFO: Model checkpoint saved at epoch: 24\n",
      "[12/23 18:48:54] __main__ INFO: Epoch: 24, GradMatch subset selection finished, takes 2351.3233. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:03,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 19:52:11] __main__ INFO: Epoch: 25 , Valid Loss: 462.58750951 , Valid Accuracy: 0.9132 , Timing: 6134.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:02:59,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 20:55:25] __main__ INFO: Epoch: 26 , Valid Loss: 465.91543555 , Valid Accuracy: 0.9074 , Timing: 3779.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:03:39,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 21:59:19] __main__ INFO: Epoch: 27 , Valid Loss: 472.57532549 , Valid Accuracy: 0.9101 , Timing: 3819.51\n",
      "[12/23 21:59:19] __main__ INFO: Model checkpoint saved at epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:08:57,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23 23:08:31] __main__ INFO: Epoch: 28 , Valid Loss: 467.86629421 , Valid Accuracy: 0.9100 , Timing: 4137.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:09:51,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/24 00:18:37] __main__ INFO: Epoch: 29 , Valid Loss: 459.24658507 , Valid Accuracy: 0.9124 , Timing: 4191.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8412it [1:09:30,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/24 01:28:23] __main__ INFO: Epoch: 30 , Valid Loss: 467.40695083 , Valid Accuracy: 0.9111 , Timing: 4170.05\n",
      "[12/24 01:28:23] __main__ INFO: Model checkpoint saved at epoch: 30\n",
      "[12/24 01:28:23] __main__ INFO: GLISTER Selection Run---------------------------------\n",
      "[12/24 01:28:23] __main__ INFO: Final SubsetTrn: 9044.103189\n",
      "[12/24 01:28:23] __main__ INFO: Valid Loss: 467.41 , Validation Accuracy: 0.91\n",
      "[12/24 01:28:23] __main__ INFO: ---------------------------------------------------------------------\n",
      "[12/24 01:28:23] __main__ INFO: GLISTER\n",
      "[12/24 01:28:23] __main__ INFO: ---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "################################################# Training Loop #################################################\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    subtrn_loss = 0\n",
    "    subtrn_correct = 0\n",
    "    subtrn_total = 0\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for _, (inputs, targets, weights) in tqdm(enumerate(dataloader), ncols=50):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # targets = targets.to(device, non_blocking=True)\n",
    "        weights = weights.to(device)  \n",
    "        \n",
    "        if 'augment_pipeline' in config_args:\n",
    "            with torch.no_grad():\n",
    "                wavs_aug_tot = []\n",
    "                labels_aug_tot = []\n",
    "                weights_aug_tot = []\n",
    "                \n",
    "                wavs_aug_tot.append(inputs.cuda()) # data_shape [batch, 1,1,time]\n",
    "                labels_aug_tot.append(targets.cuda())\n",
    "                weights_aug_tot.append(weights.cuda())\n",
    "                \n",
    "                wavs = inputs.squeeze().cuda()\n",
    "                wav_label = targets.squeeze().cuda()\n",
    "                wav_weights = weights.squeeze().cuda()\n",
    "                \n",
    "                augs_idx = np.random.choice(len(augment_pipeline), size=num_pipes, replace=False)\n",
    "                augs_idx = set(augs_idx)\n",
    "                augs = [augment_pipeline[i] for i in augs_idx]\n",
    "                sample_idxs = [np.arange(len(wavs))] * len(augs_idx)\n",
    "\n",
    "                for data_idx, augment in zip(sample_idxs, augs):\n",
    "                    # Apply augment\n",
    "                    wavs_aug = augment(wavs[data_idx], torch.tensor([1.0]*len(wavs)).cuda())\n",
    "                    # Managing speed change\n",
    "                    if wavs_aug.shape[1] > wavs.shape[1]:\n",
    "                        wavs_aug = wavs_aug[:, 0 : wavs.shape[1]]\n",
    "                    else:\n",
    "                        zero_sig = torch.zeros_like(wavs)\n",
    "                        zero_sig[:, 0 : wavs_aug.shape[1]] = wavs_aug\n",
    "                        wavs_aug = zero_sig\n",
    "\n",
    "                    if 'concat_augment' in config_args and config_args['concat_augment']:\n",
    "                        wavs_aug_tot.append(wavs_aug.unsqueeze(1).unsqueeze(1))\n",
    "                        labels_aug_tot.append(wav_label[data_idx])\n",
    "                        weights_aug_tot.append(wav_weights[data_idx].cuda())\n",
    "                    else:\n",
    "                        wavs = wavs_aug\n",
    "                        wavs_aug_tot[0] = wavs_aug.unsqueeze(1).unsqueeze(1)\n",
    "                        labels_aug_tot[0] = wav_label[data_idx]\n",
    "                \n",
    "                inputs = torch.cat(wavs_aug_tot, dim=0)\n",
    "                targets = torch.cat(labels_aug_tot)\n",
    "                weights = torch.cat(weights_aug_tot, dim=0)\n",
    "                \n",
    "        # print(inputs)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, feats = model(inputs)\n",
    "        losses  = model.loss((outputs, feats), targets)\n",
    "        loss = torch.dot(losses, weights/(weights.sum()))\n",
    "        loss.backward()\n",
    "        \n",
    "        subtrn_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        _, predicted = outputs.max(1)\n",
    "        subtrn_total += targets.size(0)\n",
    "        subtrn_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    epoch_time = time.time() - start_time\n",
    "    timing.append(epoch_time)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ################################################# Evaluation Loop #################################################\n",
    "    \"\"\"\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        trn_loss, trn_correct, trn_total = 0, 0, 0\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        tst_correct, tst_total, tst_loss = 0, 0, 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    \n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    trn_loss += loss.item()\n",
    "                    if \"trn_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        trn_total += targets.size(0)\n",
    "                        trn_correct += predicted.eq(targets).sum().item()\n",
    "                        \n",
    "                trn_losses.append(trn_loss)\n",
    "\n",
    "            if \"trn_acc\" in print_args:\n",
    "                trn_acc.append(trn_correct / trn_total)\n",
    "\n",
    "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    # outputs = model(inputs)\n",
    "                    # loss = criterion(outputs, targets)\n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    val_loss += loss.mean().item()\n",
    "                    if \"val_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_total += targets.size(0)\n",
    "                        val_correct += predicted.eq(targets).sum().item()\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            if \"val_acc\" in print_args:\n",
    "                val_acc.append(val_correct / val_total)\n",
    "\n",
    "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
    "            with torch.no_grad():\n",
    "                for _, (inputs, targets) in enumerate(valid_loader):\n",
    "                    inputs, targets = inputs.to(device), \\\n",
    "                                      targets.to(device, non_blocking=True)\n",
    "                    \n",
    "                    # outputs = model(inputs)\n",
    "                    # loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    outputs, feats = model(inputs)\n",
    "                    loss  = model.loss((outputs, feats), targets)\n",
    "                    \n",
    "                    tst_loss += loss.mean().item()\n",
    "                    if \"tst_acc\" in print_args:\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        tst_total += targets.size(0)\n",
    "                        tst_correct += predicted.eq(targets).sum().item()\n",
    "                tst_losses.append(tst_loss)\n",
    "\n",
    "            if \"tst_acc\" in print_args:\n",
    "                tst_acc.append(tst_correct / tst_total)\n",
    "\n",
    "        if \"subtrn_acc\" in print_args:\n",
    "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
    "\n",
    "        if \"subtrn_losses\" in print_args:\n",
    "            subtrn_losses.append(subtrn_loss)\n",
    "\n",
    "        print_str = \"Epoch: \" + str(epoch + 1)\n",
    "\n",
    "        \"\"\"\n",
    "        ################################################# Results Printing #################################################\n",
    "        \"\"\"\n",
    "\n",
    "        for arg in print_args:\n",
    "\n",
    "            if arg == \"val_loss\":\n",
    "                print_str += \" , \" + \"Valid Loss: {:.8f}\".format(val_losses[-1])\n",
    "\n",
    "            if arg == \"val_acc\":\n",
    "                print_str += \" , \" + \"Valid Accuracy: {:.4f}\".format(val_acc[-1])\n",
    "\n",
    "            if arg == \"tst_loss\":\n",
    "                print_str += \" , \" + \"Test Loss: {:.8f}\".format(tst_losses[-1])\n",
    "\n",
    "            if arg == \"tst_acc\":\n",
    "                print_str += \" , \" + \"Test Accuracy: {:.4f}\".format(tst_acc[-1])\n",
    "\n",
    "            if arg == \"trn_loss\":\n",
    "                print_str += \" , \" + \"Train Loss: {:.8f}\".format(trn_losses[-1])\n",
    "\n",
    "            if arg == \"trn_acc\":\n",
    "                print_str += \" , \" + \"Train Accuracy: {:.4f}\".format(trn_acc[-1])\n",
    "\n",
    "            if arg == \"subtrn_loss\":\n",
    "                print_str += \" , \" + \"Subset Loss: {:.8f}\".format(subtrn_losses[-1])\n",
    "\n",
    "            if arg == \"subtrn_acc\":\n",
    "                print_str += \" , \" + \"Subset Accuracy: {:.4f}\".format(subtrn_acc[-1])\n",
    "\n",
    "            if arg == \"time\":\n",
    "                print_str += \" , \" + \"Timing: {:.2f}\".format(timing[-1])\n",
    "\n",
    "        logger.info(print_str)\n",
    "\n",
    "    \"\"\"\n",
    "    ################################################# Checkpoint Saving #################################################\n",
    "    \"\"\"\n",
    "\n",
    "    if ((epoch + 1) % save_every == 0) and is_save:\n",
    "\n",
    "        metric_dict = {}\n",
    "\n",
    "        for arg in print_args:\n",
    "            if arg == \"val_loss\":\n",
    "                metric_dict['val_loss'] = val_losses\n",
    "            if arg == \"val_acc\":\n",
    "                metric_dict['val_acc'] = val_acc\n",
    "            if arg == \"tst_loss\":\n",
    "                metric_dict['tst_loss'] = tst_losses\n",
    "            if arg == \"tst_acc\":\n",
    "                metric_dict['tst_acc'] = tst_acc\n",
    "            if arg == \"trn_loss\":\n",
    "                metric_dict['trn_loss'] = trn_losses\n",
    "            if arg == \"trn_acc\":\n",
    "                metric_dict['trn_acc'] = trn_acc\n",
    "            if arg == \"subtrn_loss\":\n",
    "                metric_dict['subtrn_loss'] = subtrn_losses\n",
    "            if arg == \"subtrn_acc\":\n",
    "                metric_dict['subtrn_acc'] = subtrn_acc\n",
    "            if arg == \"time\":\n",
    "                metric_dict['time'] = timing\n",
    "\n",
    "        ckpt_state = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': model.loss,\n",
    "            'metrics': metric_dict\n",
    "        }\n",
    "\n",
    "        # save checkpoint\n",
    "        save_ckpt(ckpt_state, results_dir + '/model.pt')\n",
    "        logger.info(\"Model checkpoint saved at epoch: {0:d}\".format(epoch + 1))\n",
    "\n",
    "\"\"\"\n",
    "################################################# Results Summary #################################################\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"{0:s} Selection Run---------------------------------\".format(selection_strategy))\n",
    "logger.info(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
    "if \"val_loss\" in print_args:\n",
    "    if \"val_acc\" in print_args:\n",
    "        logger.info(\"Valid Loss: %.2f , Validation Accuracy: %.2f\", val_loss, val_acc[-1])\n",
    "    else:\n",
    "        logger.info(\"Valid Loss: %.2f\", val_loss)\n",
    "\n",
    "if \"tst_loss\" in print_args:\n",
    "    if \"tst_acc\" in print_args:\n",
    "        logger.info(\"Test Loss: %.2f, Test Accuracy: %.2f\", tst_loss, tst_acc[-1])\n",
    "    else:\n",
    "        logger.info(\"Test Data Loss: %f\", tst_loss)\n",
    "        \n",
    "logger.info('---------------------------------------------------------------------')\n",
    "logger.info(selection_strategy)\n",
    "logger.info('---------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5532d25d-5e5e-41d9-90cd-a3cc650484c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/24 01:28:23] __main__ INFO: Valid Accuracy, 0.5465391108610017 , 0.7178390545863815 , 0.7645469893078222 , 0.830275745638717 , 0.8688801350590883 , 0.8864378165447383 , 0.8837366347777152 , 0.8716938660664041 , 0.8657287563308947 , 0.8804727068092291 , 0.8894766460326393 , 0.9065841305571187 , 0.904108047270681 , 0.8973550928531232 , 0.8956668542487338 , 0.8990433314575127 , 0.9057962858750703 , 0.909510410804727 , 0.908047270680923 , 0.9044456949915588 , 0.9061339335959482 , 0.9122115925717501 , 0.9106359032076533 , 0.9104108047270681 , 0.9132245357343838 , 0.9073719752391671 , 0.9100731570061902 , 0.9099606077658976 , 0.9124366910523354 , 0.9110861001688239\n",
      "[12/24 01:28:23] __main__ INFO: [3834.0174107551575, 3879.671412229538, 3895.0117399692535, 3898.5775814056396, 3928.8529584407806, 3916.9818153381348, 6317.545469522476, 3927.5469286441803, 3770.271407365799, 3782.367970228195, 3794.853882789612, 3788.9934883117676, 6102.638122320175, 3748.33650970459, 3754.757301568985, 3792.051862478256, 3783.726875066757, 3796.242780447006, 6147.52587389946, 3800.96523976326, 3788.8030486106873, 3792.391788482666, 3789.7077231407166, 3787.5971705913544, 6134.982270240784, 3779.9037783145905, 3819.512831926346, 4137.342787981033, 4191.563886642456, 4170.045496940613]\n",
      "[12/24 01:28:23] __main__ INFO: Total time taken by GLISTER = 0.0000 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "################################################# Final Results Logging #################################################\n",
    "\"\"\"\n",
    "\n",
    "if \"val_acc\" in print_args:\n",
    "    val_str = \"Valid Accuracy, \" + \" , \".join([str(val) for val in val_acc])\n",
    "    logger.info(val_str)\n",
    "\n",
    "if \"tst_acc\" in print_args:\n",
    "    tst_str = \"Test Accuracy, \" + \" , \".join([str(tst) for tst in tst_acc])\n",
    "    logger.info(tst_str)\n",
    "\n",
    "if \"time\" in print_args:\n",
    "    time_str = \"Time, \" + \" , \".join([str(t) for t in timing])\n",
    "    logger.info(timing)\n",
    "\n",
    "timing_array = np.array(timing)\n",
    "cum_timing = list(generate_cumulative_timing(timing_array))\n",
    "logger.info(\"Total time taken by %s = %.4f \", selection_strategy, cum_timing[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d9a92-1b5e-429b-97a5-5fa7aa9f5ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cords",
   "language": "python",
   "name": "cords"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
