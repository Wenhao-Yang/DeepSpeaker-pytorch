{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f150889-43bc-460e-8a14-cf597d7a9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import kaldiio\n",
    "from kaldiio import ReadHelper\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1431960c-6dba-4fb8-9565-a0067895d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Define_Model.ResNet import ThinResNet\n",
    "from Define_Model.Loss.SoftmaxLoss import AdditiveMarginLinear\n",
    "from Process_Data.audio_processing import read_WaveInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0972a97e-568a-4486-90b4-848faf6c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = '/home/yangwenhao/local/project/SpeakerVerification-pytorch'\n",
    "lstm_dir = '/home/yangwenhao/local/project/lstm_speaker_verification'\n",
    "\n",
    "kwargs = {'num_workers': 8, 'pin_memory': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d14259b1-b80f-4d0d-8201-5fb60efbb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'vox1'\n",
    "uid2path  = {}\n",
    "with open(lstm_dir + '/data/%s/dev/wav.scp' % (dataset), 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        uid, upath = l.split()\n",
    "        uid2path[uid] = upath\n",
    "\n",
    "sid2utt  = {} \n",
    "with open(lstm_dir + '/data/%s/dev/spk2utt' % (dataset), 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        s_lst = l.split()\n",
    "        sid2utt[s_lst[0]] = s_lst[1:]\n",
    "\n",
    "spks = list(sid2utt.keys())\n",
    "random.shuffle(spks)\n",
    "numofspk = 20\n",
    "numofutt = 100\n",
    "target_spks = spks[:numofspk]\n",
    "\n",
    "all_data = []\n",
    "for s in target_spks:\n",
    "    for u in sid2utt[s][:numofutt]:\n",
    "        path = uid2path[u]\n",
    "        all_data.append([u, read_WaveInt(path)])\n",
    "        \n",
    "sid2idx = {s:i for i,s in enumerate(target_spks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e88f78-8570-4c1e-ab92-c1fe966fff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThinResNet(\n",
       "  (input_mask): Sequential(\n",
       "    (0): MelFbankLayer(sr=16000, num_filter=40, stretch_ratio=1.00)\n",
       "    (1): Mean_Norm(dim=-2)\n",
       "  )\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=[2, 1], padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (encoder): SelfAttentionPooling_v2(\n",
       "    (attention_linear): Linear(in_features=1280, out_features=128, bias=True)\n",
       "    (Tanh): Tanh()\n",
       "    (attention_vector): Linear(in_features=128, out_features=1280, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): AdditiveMarginLinear(feat_dim=256.000000, num_classes=1211, normalize=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ThinResNet(resnet_size=18, num_classes=1211, \n",
    "                 input_norm='Mean', input_len=300, input_dim=40, \n",
    "                 filter='fbank', feat_dim=40, sr=16000, stretch_ratio=[1.0], win_length=int(0.025*16000),\n",
    "                 nfft=512, kernel_size=5, stride=[2,1], padding=2, first_bias=True, \n",
    "                 block_type='basic', expansion=1, channels=[16, 32, 64, 128], fast='none1', downsample='k3', \n",
    "                 dropout_p=0.1, \n",
    "                 encoder_type='SAP2', time_dim=1, avg_size=0, embedding_size=256, alpha=0,\n",
    "                 mask='None', mask_len=[5, 10], init_weight='mel', scale=0.2, weight_p=0.1, weight_norm='max',\n",
    "                 mix='mixup',)\n",
    "model.classifier = AdditiveMarginLinear(feat_dim=256, num_classes=1211)\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb9f026-e82c-4a0a-9e63-30a7d4c9c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([257, 40])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_mask[0].t.mel_scale.fb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eaa590-ca5b-46f5-8128-b56641951043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████▌                                                        | 7/59 [01:13<09:12, 10.63s/it]"
     ]
    }
   ],
   "source": [
    "all_vectors = {}\n",
    "resnet_type = '/Data/checkpoint/ThinResNet18/Mean_batch256_basic_downk3_avg0_SAP2_em256_dp01_alpha0_none1_wde4_esmix2'\n",
    "model_paths = ['/arcsoft_sgd_rop/vox1/wave_fb40_dist2/123456',\n",
    "              '/arcsoft_adam_rop/vox1/wave_fb40_dist2/123456',\n",
    "              '/arcsoft_adam_cyclic/vox1/wave_fb40_dist2/123456/']\n",
    "\n",
    "model_path = model_paths[2]\n",
    "for epoch in tqdm(range(1, 60), ncols=100):\n",
    "    vectors = []\n",
    "    checkpoint = script_dir + resnet_type + model_path +'/checkpoint_%d.pth'%epoch\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(epoch, end=' ')\n",
    "        continue\n",
    "        \n",
    "    model.load_state_dict(torch.load(checkpoint)['state_dict'])\n",
    "    # model.eval()\n",
    "    for u, x in all_data:\n",
    "        data = torch.tensor(x).cuda().reshape(1, 1, 1, -1)\n",
    "        _, embededings = model(data)\n",
    "        vectors.append([u, embededings.detach().cpu().numpy()[0]])\n",
    "    \n",
    "    all_vectors[epoch] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24693e-6229-45d0-8d4b-b9f9904dbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(all_vectors.keys())\n",
    "epochs.sort()\n",
    "\n",
    "labels = np.array([sid2idx[u.split('-')[0]] for u,_ in all_vectors[1]])\n",
    "indexs = [np.where(labels==i)[0].min() for i in range(10)]\n",
    "indexs.append(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba70e3-3cc6-49a2-a2d2-01f4b81ce7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_embeds = []\n",
    "\n",
    "for e in epochs:\n",
    "    embeds = [em for u, em in all_vectors[e]]\n",
    "    embeds = np.array(embeds)\n",
    "    epoch_embeds.append(embeds)\n",
    "\n",
    "epoch_embeds = np.array(epoch_embeds)\n",
    "# print(epoch_embeds.shape)\n",
    "\n",
    "speaker_prototype = []\n",
    "for i in range(1, len(indexs)):\n",
    "    prototype = epoch_embeds[:, indexs[i-1]:indexs[i], :].mean(axis=1)\n",
    "    # print(prototype.shape)\n",
    "    speaker_prototype.append(prototype)\n",
    "    \n",
    "speaker_prototype = torch.tensor(np.array(speaker_prototype))\n",
    "# print(speaker_prototype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22329993-94b3-4364-b911-f1f0353142da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.nn.CosineSimilarity(dim=-1)\n",
    "relative_dists = dist(speaker_prototype[:, 1:], speaker_prototype[:, :-1]).mean(dim=0)\n",
    "abs_dists = dist(speaker_prototype[:, :-1], speaker_prototype[:, -1].unsqueeze(1).repeat(1,speaker_prototype.shape[1]-1,1)).mean(dim=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(epochs[1:], relative_dists.arccos())\n",
    "plt.plot(epochs[1:], abs_dists.arccos())\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Theta')\n",
    "plt.legend(['previous', 'last'])\n",
    "plt.savefig('prototype/v1_adamcyc.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
