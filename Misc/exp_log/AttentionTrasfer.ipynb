{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c983ae-7f81-44a2-984a-86806b1a0113",
   "metadata": {},
   "source": [
    "## Attention Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf550426-0abc-4d93-a2d0-10200023588e",
   "metadata": {},
   "source": [
    "### I. Method\n",
    "\n",
    "#### 1. Types of attention transfer \n",
    "  \n",
    "```\n",
    "    # feat: avg on channel  \n",
    "    feat_vec = F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "    \n",
    "    # feat_time: avg on channel and frequency  \n",
    "    feat_vec = F.normalize(x.pow(2).mean(1).mean(2).view(x.size(0), -1))\n",
    "    \n",
    "    # feat_frequency: avg on channel and time  \n",
    "    feat_vec = F.normalize(x.pow(2).mean(1).mean(1).view(x.size(0), -1))\n",
    "```\n",
    "\n",
    "#### 2. Layer-CAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811621a-7f55-4f0a-9631-a77a16f50b90",
   "metadata": {},
   "source": [
    "### II. Comparison\n",
    "\n",
    "#### 1. Attention in frequency and time axis\n",
    "\n",
    "Baseline Setting: \n",
    "* @Model: chn16 batch256_seblock_red2_downk3_avg5_ASTP2_em256_dp01_alpha0_none1_wd5e4_vares\n",
    "* @Teacher: ResNet34 \n",
    "* @Student: ResNet10\n",
    "* @Features: fbank40\n",
    "\n",
    "\n",
    "| System      |  Description  |       Testset     |     EER     |    MinDCF08   |    MinDCF10   |\n",
    "| :---------- | :-----------: | :---------------: | ----------: | ------------: | ------------: |\n",
    "| baseline    |    teacher    |     vox1-test     |  3.66±0.08  | 0.3703±0.0248 | 0.4460±0.0231 |\n",
    "|             |    student    |     vox1-test     |  4.25±0.10  | 0.3914±0.0040 | 0.5287±0.0207 |\n",
    "|     AT      |       -       |     vox1-test     |  4.05±0.04  | 0.3961±0.0076 | 0.4839±0.0299 |\n",
    "|     AT-f    |   frequency   |     vox1-test     |  4.09±0.05  | 0.3876±0.0100 | 0.5330±0.0131 |\n",
    "|     AT-t    |     time      |     vox1-test     |  4.26±0.04  | 0.4033±0.0139 | 0.4873±0.0125 |\n",
    "\n",
    "\n",
    "Considering EER and MinDCF10, Attention Transfer improves the performance of students ( AT, AT-f ). However, the student ( AT-t ) is wrose than the baseline student. The reason could be that time transfering degrade the recognition process.\n",
    "\n",
    "\n",
    "#### 2. Attention in multi-layer ( Layer-CAM )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
