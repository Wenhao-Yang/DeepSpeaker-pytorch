{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = '/home/work2020/yangwenhao/project/SpeakerVerification-pytorch'\n",
    "lstm_dir = '/home/work2020/yangwenhao/project/lstm_speaker_verification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdnn_arc = '/Data/xvector/TDNN_v5/cnceleb/klfb_egs_baseline/arcsoft/Mean_STAP_em512_wd5e4_var/train/epoch_50/scores'\n",
    "\n",
    "score_file = script_dir+tdnn_arc\n",
    "\n",
    "scores = []\n",
    "with open(score_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        s,l = line.split()\n",
    "        \n",
    "        s = float(s)\n",
    "        l = True if l=='True' else False\n",
    "            \n",
    "        scores.append((s, l))\n",
    "\n",
    "trials_file = lstm_dir + '/data/cnceleb/klfb/dev_fb40/trials_2w'\n",
    "trials = []\n",
    "\n",
    "with open(trials_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        s1,s2,l = line.split()\n",
    "\n",
    "        trials.append((s1,s2,l))\n",
    "        \n",
    "assert len(trials) == len(scores), print(len(trials), len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_utt = []\n",
    "\n",
    "for i, (s,l) in enumerate(scores):\n",
    "    if s<=0.1678 and l == True:\n",
    "        miss_utt.append((trials[i], s))\n",
    "        \n",
    "    if s>0.1678 and l == False:\n",
    "        miss_utt.append((trials[i], s))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(miss_utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'miss_utt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8489a62f4db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmiss_utt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# id00117-speech-03-011         id00175-play-02-001', 'nontarget'), 0.29571417          false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# id00496-interview-02-021      id00403-singing-03-008', 'nontarget'), 0.29446614       false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# id00648-interview-01-001      id00648-interview-01-031', 'target'), 0.12946852),      true        too short nospeaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# id00653-interview-01-001      id00653-speech-01-004', 'target'), 0.122665),           true        too short nospeaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'miss_utt' is not defined"
     ]
    }
   ],
   "source": [
    "miss_utt[:1]\n",
    "# id00117-speech-03-011         id00175-play-02-001', 'nontarget'), 0.29571417          false\n",
    "# id00496-interview-02-021      id00403-singing-03-008', 'nontarget'), 0.29446614       false  \n",
    "# id00648-interview-01-001      id00648-interview-01-031', 'target'), 0.12946852),      true        too short nospeaker\n",
    "# id00653-interview-01-001      id00653-speech-01-004', 'target'), 0.122665),           true        too short nospeaker\n",
    "# id00414-live_broadcast-02-001 id00414-live_broadcast-02-003', 'target') 0.06555986),  false       short\n",
    "# id00750-entertainment-01-001  id00750-interview-01-012', 'target' 0.07762285),        false       too hard?\n",
    "# id00750-entertainment-01-001  id00750-interview-01-015', 'target') 0.028585691),      false       too hard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 488632 missed pairs of utterance.\n"
     ]
    }
   ],
   "source": [
    "thin_arc = '/Data/xvector/ThinResNet18/cnceleb/klfb_egs_baseline/arcsoft_sgd_rop/Mean_batch256_basic_downk3_none1_SAP2_dp01_alpha0_em512_wd5e4_var/cnceleb_test_fix/score.2022.03.10.15:48:51'\n",
    "\n",
    "score_file = script_dir+thin_arc\n",
    "\n",
    "scores = []\n",
    "with open(score_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        l,s = line.split()\n",
    "        \n",
    "        s = float(s)\n",
    "        l = True if l=='True' else False\n",
    "            \n",
    "        scores.append((s, l))\n",
    "\n",
    "trials_file = lstm_dir + '/data/cnceleb/klfb/test_fb40/trials'\n",
    "trials = []\n",
    "\n",
    "with open(trials_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        s1,s2,l = line.split()\n",
    "\n",
    "        trials.append((s1,s2,l))\n",
    "        \n",
    "assert len(trials) == len(scores), print(len(trials), len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 488632 missed pairs of utterance.\n"
     ]
    }
   ],
   "source": [
    "miss_utt = []\n",
    "threshold = 0.1398\n",
    "\n",
    "for i, (s,l) in enumerate(scores):\n",
    "    if s<=threshold and l == True:\n",
    "        miss_utt.append((trials[i], s))\n",
    "        \n",
    "    if s>threshold and l == False:\n",
    "        miss_utt.append((trials[i], s))\n",
    "\n",
    "print(\"There are %d missed pairs of utterance.\" % len(miss_utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of miss pairs is 212281\n",
      "The number of miss utterances in eval is 8341\n",
      "('id00800-enroll', 'id00801-drama-01-001', '0', 0.15782022)\n"
     ]
    }
   ],
   "source": [
    "test_miss_utt_lee4s = []\n",
    "miss_eval_utt = set()\n",
    "for (a,b,t),s in miss_utt:\n",
    "    if b in less_than4s:\n",
    "        test_miss_utt_lee4s.append((a,b,t,s))\n",
    "        miss_eval_utt.add(b)\n",
    "        \n",
    "print('The number of miss pairs is %d' % len(test_miss_utt_lee4s))\n",
    "print('The number of miss utterances in eval is %d' % len(miss_eval_utt))\n",
    "\n",
    "print(test_miss_utt_lee4s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id00800-singing-01-004', 'id00800-speech-01-009', 'id00800-speech-01-011']\n"
     ]
    }
   ],
   "source": [
    "miss_eval_utt_lst = list(miss_eval_utt)\n",
    "miss_eval_utt_lst.sort()\n",
    "\n",
    "test_miss_utt_lee4s = np.array(test_miss_utt_lee4s)\n",
    "print(miss_eval_utt_lst[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id00912-enroll' 'id00800-singing-01-004' '0' '0.2134133']\n",
      " ['id00909-enroll' 'id00800-singing-01-004' '0' '0.17836496']\n",
      " ['id00906-enroll' 'id00800-singing-01-004' '0' '0.17403042']\n",
      " ['id00831-enroll' 'id00800-singing-01-004' '0' '0.22168054']]\n"
     ]
    }
   ],
   "source": [
    "# test_miss_utt_lee4s = np.sort(test_miss_utt_lee4s, axis=1)\n",
    "# print(test_miss_utt_lee4s[:,1][:2])\n",
    "sort_idx = np.argsort(test_miss_utt_lee4s[:,1])\n",
    "sort_test_miss_utt_lee4s = test_miss_utt_lee4s[sort_idx]\n",
    "\n",
    "print(sort_test_miss_utt_lee4s[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0.15782022', 'id00800-enroll', 'id00801-drama-01-001'],\n",
       "       ['0', '0.19220155', 'id00800-enroll', 'id00801-drama-02-004'],\n",
       "       ['0', '0.15822154', 'id00800-enroll', 'id00802-drama-02-018'],\n",
       "       ['0', '0.1489509', 'id00800-enroll', 'id00802-speech-03-024']],\n",
       "      dtype='<U29')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_miss_utt_lee4s[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('id00800-enroll', 'id00800-singing-01-002', '1'), 0.008005224),\n",
       " (('id00800-enroll', 'id00800-singing-01-003', '1'), -0.028903881),\n",
       " (('id00800-enroll', 'id00800-singing-01-006', '1'), 0.035782717),\n",
       " (('id00800-enroll', 'id00801-drama-01-001', '0'), 0.15782022)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_utt[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnc_eval_utt2dur_file = '/home/work2020/yangwenhao/project/lstm_speaker_verification/data/cnceleb/eval/utt2dur'\n",
    "\n",
    "utt2dur = {}\n",
    "with open(cnc_eval_utt2dur_file, 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        uid, dur = l.split()\n",
    "        utt2dur[uid]=float(dur)\n",
    "\n",
    "less_dur = 4.0\n",
    "less_than4s = set()  \n",
    "for uid in utt2dur:\n",
    "    if utt2dur[uid] < less_dur:\n",
    "        less_than4s.add(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_subset_miss = set()\n",
    "for m in miss_utt:\n",
    "#     print(m)\n",
    "    (a,b,l), s = m\n",
    "    dev_subset_miss.add(a)\n",
    "    dev_subset_miss.add(b)\n",
    "    \n",
    "dev_subset_path = []\n",
    "dev_wav_scp = lstm_dir + '/data/cnceleb/klfb/dev_fb40/wav.scp'\n",
    "\n",
    "with open(dev_wav_scp, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        uid, upath = line.split()\n",
    "        if uid in dev_subset_miss:\n",
    "            dev_subset_path.append(upath)\n",
    "            \n",
    "print(len(dev_subset_path))\n",
    "\n",
    "with open(script_dir+'/Data/xvector/TDNN_v5/cnceleb/klfb_egs_baseline/arcsoft/Mean_STAP_em512_wd5e4_var/train/epoch_50/miss_wavs', 'w') as f:\n",
    "    for d in dev_subset_path:\n",
    "        f.write(d + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
